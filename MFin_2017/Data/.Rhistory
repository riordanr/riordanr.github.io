rbtc.plot(trades)
install.packages("devtools")
install.packages("data.table") # 1.9.5+
install.packages("shiny")
shiny::runGitHub("jangorecki/shinyBTC")
# if you hit pandoc error you should update it, for example by copy from RStudio:
#sudo cp /usr/lib/rstudio/bin/pandoc/* /usr/local/bin/
# optionally you can load own wallet archive before runApp
options("shinyBTC.wallet_manager.archive_path"="/path/wallet_archive.rds")
plot(trades)
rbtc.plot(trades)
Rbitcoin.plot(trades)
library(twitteR)
library(sentiment)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(twitteR)
library(sentiment)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
# harvest some tweets
some_tweets = searchTwitter("starbucks", n=1500, lang="en")
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
# remove retweet entities
some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt)
# remove at people
some_txt = gsub("@\\w+", "", some_txt)
# remove punctuation
some_txt = gsub("[[:punct:]]", "", some_txt)
# remove numbers
some_txt = gsub("[[:digit:]]", "", some_txt)
# remove html links
some_txt = gsub("http\\w+", "", some_txt)
# remove unnecessary spaces
some_txt = gsub("[ \t]{2,}", "", some_txt)
some_txt = gsub("^\\s+|\\s+$", "", some_txt)
# define "tolower error handling" function
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
some_txt = sapply(some_txt, try.error)
# remove NAs in some_txt
some_txt = some_txt[!is.na(some_txt)]
names(some_txt) = NULL
Step 4: Perform Sentiment Analysis
# classify emotion
class_emo = classify_emotion(some_txt, algorithm="bayes", prior=1.0)
# get emotion best fit
emotion = class_emo[,7]
# substitute NA's by "unknown"
emotion[is.na(emotion)] = "unknown"
# classify polarity
class_pol = classify_polarity(some_txt, algorithm="bayes")
# get polarity best fit
polarity = class_pol[,4]
Step 5: Create data frame with the results and obtain some general statistics
# data frame with results
sent_df = data.frame(text=some_txt, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
# sort data frame
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
This what the first 15 rows of sent_df would look like
# plot distribution of emotions
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets") +
opts(title = "Sentiment Analysis of Tweets about Starbucks\n(classification by emotion)",
plot.title = theme_text(size=12))
install.packages("ggplot2")
library(twitteR)
library(sentiment)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
# harvest some tweets
some_tweets = searchTwitter("starbucks", n=1500, lang="en")
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
# remove retweet entities
some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt)
# remove at people
some_txt = gsub("@\\w+", "", some_txt)
# remove punctuation
some_txt = gsub("[[:punct:]]", "", some_txt)
# remove numbers
some_txt = gsub("[[:digit:]]", "", some_txt)
# remove html links
some_txt = gsub("http\\w+", "", some_txt)
# remove unnecessary spaces
some_txt = gsub("[ \t]{2,}", "", some_txt)
some_txt = gsub("^\\s+|\\s+$", "", some_txt)
# define "tolower error handling" function
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
some_txt = sapply(some_txt, try.error)
# remove NAs in some_txt
some_txt = some_txt[!is.na(some_txt)]
names(some_txt) = NULL
Step 4: Perform Sentiment Analysis
# classify emotion
class_emo = classify_emotion(some_txt, algorithm="bayes", prior=1.0)
# get emotion best fit
emotion = class_emo[,7]
# substitute NA's by "unknown"
emotion[is.na(emotion)] = "unknown"
# classify polarity
class_pol = classify_polarity(some_txt, algorithm="bayes")
# get polarity best fit
polarity = class_pol[,4]
Step 5: Create data frame with the results and obtain some general statistics
# data frame with results
sent_df = data.frame(text=some_txt, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
# sort data frame
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
This what the first 15 rows of sent_df would look like
# plot distribution of emotions
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette="Dark2") +
labs(x="emotion categories", y="number of tweets") +
opts(title = "Sentiment Analysis of Tweets about Starbucks\n(classification by emotion)",
plot.title = theme_text(size=12))
# harvest some tweets
some_tweets = searchTwitter("starbucks", n=1500, lang="en")
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
# remove retweet entities
some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt)
# remove at people
some_txt = gsub("@\\w+", "", some_txt)
# remove punctuation
some_txt = gsub("[[:punct:]]", "", some_txt)
# remove numbers
some_txt = gsub("[[:digit:]]", "", some_txt)
# remove html links
some_txt = gsub("http\\w+", "", some_txt)
# remove unnecessary spaces
some_txt = gsub("[ \t]{2,}", "", some_txt)
some_txt = gsub("^\\s+|\\s+$", "", some_txt)
# harvest some tweets
some_tweets = searchTwitter("starbucks", n=1500, lang="en")
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
# remove retweet entities
some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt)
# remove at people
some_txt = gsub("@\\w+", "", some_txt)
# remove punctuation
some_txt = gsub("[[:punct:]]", "", some_txt)
# remove numbers
some_txt = gsub("[[:digit:]]", "", some_txt)
# remove html links
some_txt = gsub("http\\w+", "", some_txt)
# remove unnecessary spaces
some_txt = gsub("[ \t]{2,}", "", some_txt)
some_txt = gsub("^\\s+|\\s+$", "", some_txt)
some_tweets = searchTwitter("starbucks", n=1500, lang="en")
library(twitteR)
install.packages("twitteR")
library(twitteR)
library(sentiment)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
# harvest some tweets
some_tweets = searchTwitter("starbucks", n=1500, lang="en")
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
install.packages("sentiment")
install.packages("sentimentr")
library(twitteR)
library(sentiment)
library(plyr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
# harvest some tweets
some_tweets = searchTwitter("starbucks", n=1500, lang="en")
# get the text
some_txt = sapply(some_tweets, function(x) x$getText())
library(twitteR)
library(ROAuth)
library(httr)
install.packages("ROAuth")
library(twitteR)
library(ROAuth)
library(httr)
tweets_sanders <- searchTwitter('@BernieSanders', n=1500)
# Set API Keys
api_key <- "PNfWTS6NSUp6QxjOlKqRw"
api_secret <- "jd1UL9o6KOwA9Lw8u18gcaRMWs2V0eb8IRVIWMCeEQ"
access_token <- "930629347-CekJ5yTx6hnKHq8HE3yNYAjycjtWvq864DuhSL6L"
access_token_secret <- "ZP888Xoj9D09xdkUZMepg1jlSJJDkDcS7sUvgFNH09fUH"
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
tweets_sanders <- searchTwitter('@BernieSanders', n=1500)
library(plyr)
feed_sanders = laply(tweets_sanders, function(t) t$getText())
yay = scan('../Data/opinion-lexicon-English/positive-words.txt', what='character', comment.char=';')
boo = scan('../Data/opinion-lexicon-English/negative-words.txt', what='character', comment.char=';')
yay = scan('../Data/opinion-lexicon-English/positive-words.txt', what='character', comment.char=';')
boo = scan('../Data/opinion-lexicon-English/negative-words.txt', what='character', comment.char=';')
yay = scan('/Users/ryanriordan/Dropbox (School of Business)/Teaching/Queens/Winter2017/FinTech_MFin/Data/opinion-lexicon-English/positive-words.txt
', what='character', comment.char=';')
b
yay = scan('/Users/ryanriordan/Dropbox (School of Business)/Teaching/Queens/Winter2017/FinTech_MFin/Data/opinion-lexicon-English/positive-words.txt
', what='character', comment.char=';')
yay = scan("/Users/ryanriordan/Dropbox (School of Business)/Teaching/Queens/Winter2017/FinTech_MFin/Data/opinion-lexicon-English/positive-words.txt", what='character', comment.char=';')
cwd("/Users/ryanriordan/Dropbox (School of Business)/Teaching/Queens/Winter2017/FinTech_MFin/Data")
yay = scan("opinion-lexicon-English/positive-words.txt", what='character', comment.char=';')
dir("/Users/ryanriordan/Dropbox (School of Business)/Teaching/Queens/Winter2017/FinTech_MFin/Data")
yay = scan("opinion-lexicon-English/positive-words.txt", what='character', comment.char=';')
setwd("/Users/ryanriordan/Dropbox (School of Business)/Teaching/Queens/Winter2017/FinTech_MFin/Data")
yay = scan("opinion-lexicon-English/positive-words.txt", what='character', comment.char=';')
boo = scan('opinion-lexicon-English/negative-words.txt', what='character', comment.char=';')
# Add a few twitter-specific negative phrases
bad_text = c(boo, 'wtf', 'epicfail', 'douchebag')
good_text = c(yay, 'upgrade', ':)', '#iVoted', 'voted')
score.sentiment = function(sentences, good_text, bad_text, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, good_text, bad_text) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\d+', '', sentence)
#to remove emojis
sentence <- iconv(sentence, 'UTF-8', 'ASCII')
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, good_text)
neg.matches = match(words, bad_text)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, good_text, bad_text, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
# Call the function and return a data frame
feelthabern <- score.sentiment(feed_sanders, good_text, bad_text, .progress='text')
# Cut the text, just gets in the way
plotdat <- plotdat[c("name", "score")]
# Remove neutral values of 0
plotdat <- plotdat[!plotdat$score == 0, ]
# Nice little quick plot
qplot(factor(score), data=plotdat, geom="bar",
fill=factor(name),
xlab = "Sentiment Score")
score.sentiment = function(sentences, good_text, bad_text, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, good_text, bad_text) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\d+', '', sentence)
#to remove emojis
sentence <- iconv(sentence, 'UTF-8', 'ASCII')
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, good_text)
neg.matches = match(words, bad_text)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, good_text, bad_text, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
# Call the function and return a data frame
feelthabern <- score.sentiment(feed_sanders, good_text, bad_text, .progress='text')
# Cut the text, just gets in the way
plotdat <- plotdat[c("name", "score")]
# Remove neutral values of 0
plotdat <- plotdat[!plotdat$score == 0, ]
# Nice little quick plot
qplot(factor(score), data=plotdat, geom="bar",
fill=factor(name),
xlab = "Sentiment Score")
score.sentiment = function(sentences, good_text, bad_text, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, good_text, bad_text) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
#to remove emojis
sentence <- iconv(sentence, 'UTF-8', 'ASCII')
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, good_text)
neg.matches = match(words, bad_text)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, good_text, bad_text, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
# Call the function and return a data frame
feelthabern <- score.sentiment(feed_sanders, good_text, bad_text, .progress='text')
# Cut the text, just gets in the way
plotdat <- plotdat[c("name", "score")]
# Remove neutral values of 0
plotdat <- plotdat[!plotdat$score == 0, ]
# Nice little quick plot
qplot(factor(score), data=plotdat, geom="bar",
fill=factor(name),
xlab = "Sentiment Score")
score.sentiment = function(sentences, good_text, bad_text, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, good_text, bad_text) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
#to remove emojis
sentence <- iconv(sentence, 'UTF-8', 'ASCII')
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, good_text)
neg.matches = match(words, bad_text)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, good_text, bad_text, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
# Call the function and return a data frame
feelthabern <- score.sentiment(feed_sanders, good_text, bad_text, .progress='text')
# Cut the text, just gets in the way
plotdat <- plotdat[c("name", "score")]
# Remove neutral values of 0
plotdat <- plotdat[!plotdat$score == 0, ]
# Nice little quick plot
qplot(factor(score), data=plotdat, geom="bar",
fill=factor(name),
xlab = "Sentiment Score")
library(twitteR)
library(ROAuth)
library(httr)
# Set API Keys
api_key <- "PNfWTS6NSUp6QxjOlKqRw"
api_secret <- "jd1UL9o6KOwA9Lw8u18gcaRMWs2V0eb8IRVIWMCeEQ"
access_token <- "930629347-CekJ5yTx6hnKHq8HE3yNYAjycjtWvq864DuhSL6L"
access_token_secret <- "ZP888Xoj9D09xdkUZMepg1jlSJJDkDcS7sUvgFNH09fUH"
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
# Grab latest tweets
tweets_sanders <- searchTwitter('@BernieSanders', n=1500)
# Loop over tweets and extract text
library(plyr)
feed_sanders = laply(tweets_sanders, function(t) t$getText())
# Okay now we have the Tweets let's do some analysis of them
# Read in dictionary of positive and negative works
setwd("/Users/ryanriordan/Dropbox (School of Business)/Teaching/Queens/Winter2017/FinTech_MFin/Data")
yay = scan("opinion-lexicon-English/positive-words.txt", what='character', comment.char=';')
boo = scan('opinion-lexicon-English/negative-words.txt', what='character', comment.char=';')
# Add a few twitter-specific negative phrases
bad_text = c(boo, 'wtf', 'epicfail', 'douchebag')
good_text = c(yay, 'upgrade', ':)', '#iVoted', 'voted')
score.sentiment = function(sentences, good_text, bad_text, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, good_text, bad_text) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
#to remove emojis
sentence <- iconv(sentence, 'UTF-8', 'ASCII')
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, good_text)
neg.matches = match(words, bad_text)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, good_text, bad_text, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
# Call the function and return a data frame
feelthabern <- score.sentiment(feed_sanders, good_text, bad_text, .progress='text')
# Cut the text, just gets in the way
plotdat <- plotdat[c("name", "score")]
# Remove neutral values of 0
plotdat <- plotdat[!plotdat$score == 0, ]
# Nice little quick plot
qplot(factor(score), data=plotdat, geom="bar",
fill=factor(name),
xlab = "Sentiment Score")
tweets_sanders
feelthabern <- score.sentiment(feed_sanders, good_text, bad_text, .progress='text')
feelthabern
plotdat <- plotdat[c("name", "score")]
plotdat <- feelthabern[c("name", "score")]
ggplot(feelthabern, aes(x=score))
ggplot(feelthabern, aes(x=score))
# Nice little quick plot
qplot(factor(score), data=feelthabern, geom="bar",
fill=factor(name),
xlab = "Sentiment Score")
# Nice little quick plot
qplot(factor(score), data=feelthabern, geom="bar",
fill=factor(name),
xlab = "Sentiment Score")
# Nice little quick plot
qplot(factor(score), data=feelthabern, geom="line",
fill=factor(name),
xlab = "Sentiment Score")
View(feelthabern)
View(feelthabern)
